\documentclass[]{report}

\linespread{1.5}

\include{packages}
\include{macros}

% Title Page
\title{}
\author{William Bombardelli da Silva}

\begin{document}
\maketitle

\begin{abstract}
\end{abstract}

\tableofcontents
\newpage

%TODO: Decide on the use of italic
%TODO: Decide whether ms or m_s mt or m_t?
\section{Introduction}
Overview of the MDE. Potential and problems of it. The challenge of model transformation. A solution: Triple Graph Grammars (TGG) (justification). A problem of TGG (usability/ amount of grammar rules). Our solution for this problem: TGG with non-terminal nodes. Overview of our approach (graph grammars with non-terminal nodes, NCE grammars, graph language, parsing, transformation). Brief intro into graph grammars and embedding. Explain why BNCE (HRG parsers were for classes too restricted), why grammars. Short summary of the results. Remainder.

\section{Related Work}
In this section, we offer a literary review on the topics of graph grammars and triple graph grammars as well as we indicate published works that are related with our approach. Here, we focus on the node label and the hyperedge replacement approach for graph grammars. Nevertheless, the field does not restrict to this topic, instead, there is a myriad of different approaches to it, for example, the algebraic approach \cite{ehrig1999handbook}. We refer to context-free and context-sensitive grammars, inspired by the use of such classification for string grammars, in a relaxed way without any compromise to the correct definition of context-freeness for graph grammars.

\textit{Hyperedge replacement graph grammars} (HRG) are context-free grammars with semantics based on the replacement of hyperedges by hypergraphs \cite{drewes1997hyperedge} governed by morphisms. Prominent polynomial-time top-down and shift-reduce parsing techniques for classes of such grammars can be found in \cite{drewes2015predictive,drewes2017predictive,bjorklund2016between,chiang2013parsing} and applications for syntax definition of a visual language can be found in \cite{minas2006syntax,engelfriet1998tree}.

We divide the node label replacement approaches into context-sensitive and context-free approaches, we refer to context-sensitive and context-free grammars, inspired by the use of such classification for string grammars, in a relaxed way without any compromise to any definition of context-freeness for graph grammars. The context-sensitive field includes the \textit{layered graph grammar}, whose semantics consists of the replacement of graphs by other graphs governed by morphisms \cite{rekers1997defining} and for which exponential-time bottom-up parsing algorithms have been proposed \cite{rekers1995graph,bottoni2000efficient,furst2011improving}. Another context-sensitive formalism is the \textit{reserved graph grammar}, that is based on the replacement of directed graphs by necessarily greater directed graphs governed by simple embedding rules \cite{zhang2001context} and for which exponential and polynomial-time bottom-up algorithms have been proposed in \cite{zeng2005rgg+,zou2017partial}.

In the node label replacement context-free formalisms stand out the  \textit{node label controlled graph grammar} (NLC) and its successor \textit{graph grammar with neighborhood-controlled embedding} (NCE). NLC is based on the replacement of one vertex by a graph, governed by embedding rules written in terms of the vertex's label \cite{rozenberg1986boundary}. For various classes of these grammars, there exists polynomial-time top-down and bottom-up parsing algorithms \cite{flasinski1993parsing,flasinski2014characteristics, rozenberg1986boundary, wanke1991algorithms}. The recognition complexity and generation power of such grammars have also been analyzed \cite{flasinski1998power,kim2012structure}. NCE occurs in several formulations, including a context-sensitive one, but here we focus on the context-free formulation, where one vertex is replaced by a graph, and the embedding rules are written in terms of the vertex's neighbors \cite{janssens1982graph,skodinis1998neighborhood}. For some classes of these grammars, polynomial-time bottom-up parsing algorithms and automaton formalisms were proposed and analyzed \cite{kim2001efficient,brandenburg2005finite}. In special, one of these classes is the \textit{boundary graph grammar with neighborhood-controlled embedding} (BNCE), that is used to construct our own formalism. Moreover, it is worth mentioning that, according to \cite{engelfiet1990comparison}, BNCE and HRG have the same generative power.

Beyond the approaches presented above, there is a myriad of alternative proposals for graph grammars, including a context-sensitive NCE \cite{adachi1999nce}, an edge-based grammar \cite{shi2015method}, a grammar that replaces star graphs by other graphs \cite{drewes2010adaptive}, a coordinate system-based grammar \cite{kong2006spatial} and a regular graph grammar \cite{gilroy2017parsing}.

Regarding TGG \cite{schurr1994specification}, a 20 years review of the realm is put forward by Anjorin et al. \cite{anjorin201620}. In special, advances are made in the direction of expressiveness with the introduction of application conditions \cite{klar2010extended} and of modularization \cite{anjorin2014modularizing}. Furthermore, in the algebraic approach for graph grammars, we have found proposals that introduce inheritance \cite{bardohl2004integrating,hermann2008typed} and variables \cite{hoffmann2005graph} to the formalisms. Nevertheless, we do not know any approach that introduces non-terminal symbols to TGG with the purpose of gaining expressiveness or usability. In this sense our proposal brings something new to the current state-of-the-art.


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%% THEORETICAL REVIEW %%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Theoretical Review}
In this section, we introduce the theoretical concepts used along this thesis. The definitions below are taken from the works of ...%TODO: cite 27, 54,s_99.
We first go on to define graphs and graph grammars and then, building upon it, we construct the so-called triple graph grammars.

%%%==================================================================%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%% GRAPH GRAMMARS %%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%==================================================================%%%

\subsection{Graph Grammars}
We start presenting our notation for graphs and grammars, accompanied by examples, then we introduce the dynamic aspects of the graph grammar formalism that is, how graph grammars are to be interpreted.

%%%%%% Abstract Syntax %%%%%%

%TODO: Maybe change this definition layout
\begin{definition}
	\label{def:graph}
	A directed labeled graph $G$ over the finite set of symbols $\Sigma$, $G = (V, E, \phi)$ consists of a finite set of vertices $V$, a set of labeled directed edges $E \subseteq V \times \Sigma \times V$ and a total vertex labeling function $\phi : V \to \Sigma$. Directed labeled graphs are often referred to simply as graphs. For a fixed graph $G$ we refer to its components as $V_G$, $E_G$ and $\phi_G$. Moreover, we denote the set of all graphs over $\Sigma$ by $\allgraphs{\Sigma}$. In special, we do not allow loops (vertices of the form $(v,l,v)$), but multi-edges with different labels are allowed.
	%TODO: Comments about notation (e..g edge labels x vertex labels)
	
	If $\phi_G(v) = a$ we say $v$ is labeled by $a$. Two vertices $v$ and $w$ are neighbors (also adjacent) if, and only if,there is one or more edges between them, that is, $(v,\_,w) \in E_G \lor (w,\_,v) \in E_G$. Two graphs $G$ and $H$ are disjoint if, and only if,$V_G \cap V_H = \emptyset$.
	
	We define also de function $\neigh{G}: 2^{V_G} \to 2^{V_G}$, that applied to $U$ gives the set of neighbors of vertices in $U$ minus $U$. That is $\neigh{G}(U) = \{ v \in V_G \setminus U \st \text{ exists a } (v,l,u) \in E_G \text{ or a } (u,l,v) \in E_G \text{ with } u \in U \}$
\end{definition}

\begin{definition}
	\label{def:morphism}
	A morphism of graphs $G$ and $H$ is a mapping $m: V_G \to V_H$.
\end{definition}

\begin{definition}
	An isomorphism of directed labeled graphs $G$ and $H$ is a bijective mapping $m: V_G \to V_H$ that maintains the connections between vertices and their labels, that is, $(v,l,w) \in E_G$ if, and only if,  $(m(v),l,m(w)) \in E_H$ and $\phi_G(v) = \phi_H(m(v))$. In this case, $G$ and $H$ are said to be isomorphic, we write $G \isomorph H$, and we denote the equivalence class of all graphs isomorphic to G by $[G]$.
	Notice that, contrary to isomorphisms, morphism do not require bijectivity nor label or edge-preserving properties.
	%TODO: Maybe say some words about the difference to the common isomorphism
\end{definition}

\begin{definition}
	A $\Gamma\text{-boundary}$ graph $G$ is such that vertices labeled with any symbol from $\Gamma$ are not neighbors. That is, the graph $G$ is $\Gamma\text{-boundary}$ if, and only if, $\not\exists (v,\_,w) \in E_G \. \phi_G(v) \in \Gamma \land \phi_G(w) \in \Gamma$.
\end{definition}

We use graphs to represent models, first because of the extensive theory behind them and, second, because their very abstract structure suits the description of a large spectrum of practical models. In the following we introduce graph grammars, which also suit our needs very well, because they serve as a very effective tool to characterize (possibly infinite) sets of graphs using very few notation.

\begin{definition}
	\label{def:gg}
	A graph grammar with neighborhood-controlled embedding (NCE graph grammar) $GG = (\Sigma, \Delta \subseteq \Sigma, S \in \Sigma, P)$ consists of a finite set of symbols $\Sigma$ that is the alphabet, a subset of the alphabet $\Delta \subseteq \Sigma$ that holds the terminal symbols (we define the complementary set of non-terminal symbols as $\Gamma := \Sigma \setminus \Delta$), a special symbol of the alphabet $S \in \Sigma$ that is the start symbol, and a finite set of production rules $P$ of the form $(A \pro R, \omega)$ where $A \in \Gamma$ is the so-called left-hand side, $R \in \allgraphs{\Sigma}$ is the right-hand side and $\omega : V_R \pto 2^{\Sigma \times \Sigma}$ is the partial embedding function from the $R$'s vertices to pairs of edge and vertex labels. NCE graph grammars are often referred to as graph grammars or simply as grammars.
	
	For convenience, define the start graph of $GG$ as $\startG{GG} := (\{v_s\},\emptyset,\{v_s \mapsto S\})$
	%TODO: notation for the componenents? set of all grammars?
	%TODO: Comment notation: e.g. do not separate edge vertex labels
	%TODO: also say something about more general grammars (e.g. context-free)
	%TODO: Extend here with look-ahead
	%TODO: discuss empty productions
	
	Vertices from the right-hand sides of rules labeled by non-terminal (terminal) symbols are said to be non-terminal (terminal) vertices.
\end{definition}

Notice that, in the original definition of NCE grammars \cite{janssens1982graph}, the left-hand side of the productions were allowed to contain any connected graph. So, strictly speaking, the definition above characterizes actually a 1-edNCE graph grammar, that contains only one element in the left-hand side and a directed edge-labeled graph in the right-hand side. Nevertheless, for simplicity, we use the denomination NCE to mean a 1-edNCE grammar.

\begin{definition}
	A boundary graph grammar with neighborhood-controlled embedding (BNCE graph grammar) $GG$ is such that non-terminal vertices of the right-hand sides of rules are not neighbors. That is, the graph grammar $GG$ is boundary if, and only if,all its rules' right-hand sides are $\Gamma\text{-boundary}$ graphs.
\end{definition}

%%%%%% Concrete Syntax %%%%%%
In the following, we present our concrete syntax inspired by the well-known Backus-naur form to denote NCE graph grammar rules. Let $GG = (\{A, B, a, b,$ $ c, l, m\},$ $\{a, b, c, l, m\}, A, \{p,q\})$ be a graph grammar with production rules $p = (A \pro G,\omega)$ and $q = (A \pro H,\zeta)$ where $G = (\{v_1, v_2, v_3\}, \{(v_1,l,v_2), (v_2,m,v_3)\},$ $\{v_1 \mapsto B, v_2 \mapsto b, v_3 \mapsto c \})$, and $H = (\{u_1\}, \emptyset, \{u_1 \mapsto a\})$, we denote $p$ and $q$ together as\\
\input{misc/concrete-syntax}

Observe that, we use squares for non-terminal vertices, circles for terminal vertices, position the respective label inside the shape and the (possibly omitted) identifier over it. Near each edge is positioned its respective label. The embedding function is not included in the notation, so it is expressed separately, if necessary.

%TODO: comment on the different notation compared to the literature that uses attributed graphs and squares, etc... plus attributed graphs

%%%%%% Semantics %%%%%%
In the sequel, we introduce the dynamic aspects of NCE graph grammars by means of the concepts of derivation step, derivation and language.

\begin{definition}
	%TODO: Maybe define dstep more formally
	\label{def:gg_dstep}
	Let $GG = (\Sigma, \Delta, S, P)$ be a graph grammar and $G$ and $H$ be two graphs over $\Sigma$ that are disjoint to all right-hand sides from $P$, $G$ concretely derives in one step into $H$ with rule $r$ and vertex $v$, we write $G \cderiv{r}{v}{GG} H$ and call it a concrete derivation step, if, and only if, the following holds:
	\begin{align*}
		r & = (A \pro R, \omega) \in P \text{ and } A = \phi_G(v) \text{ and} \\
		V_H  & = (V_G \setminus \{v\}) \cup V_R \text{ and} \\
		E_H & = (E_G \setminus (\{(v,l,w) \st (v,l,w) \in E_G\} \cup \{(w,l,v) \st (w,l,v) \in E_G\})) \\
		& \cup E_R \\
		& \cup \{(w,l,t) \st (w,l,v) \in E_G \land (l,\phi_G(w)) \in \omega(t)\} \\
		& \cup \{(t,l,w) \st (v,l,w) \in E_G \land (l,\phi_G(w)) \in \omega(t)\} \text{ and} \\
		\phi_H & = (\phi_G \setminus \{(v,x) \st x \in \Sigma \}) \cup \phi_R
	\end{align*}
	Notice that, without loss of generality, we set $\omega(t) = \emptyset$ for all vertices $t$ without an image defined in $\omega$.
	
	If $G$ \textit{concretely derives} in one step into any graph $H'$ isomorphic to $H$, we say it \textit{derives} in one step into $H'$ and write $G \deriv{r}{v}{GG} H'$. 
	
	When $GG$, $r$ or $v$ are clear in the context or irrelevant we might omit them and simply write $G \cderiv{}{}{} H$ or $G \deriv{}{}{} H$. Moreover, we denote the reflexive transitive closure of $\deriv{}{}{}$ by $\derivtr{}$ and, for $G \derivtr{} H'$, we say $G$ derives into $H'$.
\end{definition}
%TODO: Explain precedence of vertices, descendant, sentential form
A concrete derivation can be informally understood as the replacement of a non-terminal vertex $v$ and all its adjacent edges in $G$ by a graph $R$ plus edges $e$ from former neighbors $w$ of $v$ to some vertices $t$ of $R$, provided $e$'s label and $w$'s label are in the embedding specification $\omega(t)$. That is, the embedding function $\omega$ of a rule specifies which neighbors of $v$ are to be connected with which vertices of $R$, according to their labels and the adjacent edges' labels. The process that governs the creation of these edges is called embedding and can occur in various forms in different graph grammar formalisms. We opted for a rather simple approach, in which the edges' directions and labels are maintained and cannot be used to define embedding. As an additional note, it is worth mentioning, that string grammars have no embedding because a replaced symbol in a string has ``connections" only with its left and right neighbors, so the replacement is always ``connected" with both sides.

\begin{definition}
	A derivation $D$ in the grammar $GG$ is a non-empty sequence of derivation steps and is written as
	\[ 
		D = (G_0 \deriv{r_0}{v_0}{} G_1 \deriv{r_1}{v_1}{} G_2 \deriv{r_2}{v_2}{} \dots \deriv{r_{n-1}}{v_{n-1}}{} G_n)
	\]
\end{definition}

\begin{definition}
	The language $L(GG)$ generated by the grammar $GG$ is the set of all graphs containing only terminal vertices derived from the start graph $\startG{GG}$, that is
	\[
		L(GG) = \{H \text{ is a graph over } \Delta \text{ and } \startG{GG} \derivtr{} H\}
	\]
\end{definition}

It is clear that, for every graph $G \in L(GG)$, there is at least one finite derivation $(\startG{GG} \deriv{r_0}{v_0}{} \dots \deriv{r_{n-1}}{v_{n-1}}{} G)$ with $n \ge 1$, but it is not guaranteed that this derivation be unique. In the case that there is more than one derivation for a $G$, we say that the grammar $GG$ is ambiguous.

Below we give one example of a grammar whose language consists of all chains of one or more vertices with interleaved vertices labeled with $a$ and $b$.

%Examples (chains)
\begin{example}{Chains of a's and b's.}
	$GG = (\{S,A,B,a,b,c\}, \{a,b,c\}, S, P)$, where $P = \{r_0, r_1, r_2, r_3, r_4, $ $r_5\}$ is denoted by
	
	\input{examples/abchains-gg}
	with $\omega_0 = \omega_1 = \emptyset$, $\omega_2(u_{21}) = \omega_3(u_{31}) = \{(c,b)\}$ and $\omega_4(u_{41}) = \omega_5(u_{51}) = \{(c,a)\}$ being the complete definition of the embedding functions of the rules, $r_0, r_1, r_2, r_3, r_4, r_5$ respectively.
	
	The graph $G=$
	\begin{tikzpicture}[graph]
	\draw (0,0) node[t] (v1) {a};
	\draw (1.5,0) node[t] (v2) {b};
	\draw (3,0) node[t] (v3) {a};
	\draw[edge] (v1) -- (v2) node [edgeLabel] {$c$};
	\draw[edge] (v2) -- (v3) node [edgeLabel] {$c$};
	\end{tikzpicture}
	belongs to $L(GG)$ because it contains only terminal vertices and $\startG{GG}$ derives into it using the following derivation:
	\[
		\startG{GG} \deriv{r_0}{v_0}{} 
		\begin{tikzpicture}[graph]
		\draw (0,0) node[nont, label=90:$v_1$] (v1) {A};
		\end{tikzpicture}
		\deriv{r_2}{v_1}{} 
		\begin{tikzpicture}[graph]
		\draw (1,0) node[t, label=90:$v_2$] (v2) {a};
		\draw (2,0) node[nont, label=90:$v_3$] (v3) {B};
		\draw[edge] (v2) -- (v3) node [edgeLabel] {$c$};
		\end{tikzpicture}
		\deriv{r_4}{v_3}{}
		\begin{tikzpicture}[graph]
		\draw (1,0) node[t, label=90:$v_2$] (v2) {a};
		\draw (2,0) node[t, label=90:$v_4$] (v4) {b};
		\draw (3,0) node[nont, label=90:$v_5$] (v5) {A};
		\draw[edge] (v2) -- (v4) node [edgeLabel] {$c$};
		\draw[edge] (v4) -- (v5) node [edgeLabel] {$c$};
		\end{tikzpicture}
		\deriv{r_3}{v_5}{}
		\begin{tikzpicture}[graph]
		\draw (0,0) node[t, label=90:$v_2$] (v2) {a};
		\draw (1,0) node[t, label=90:$v_4$] (v4) {b};
		\draw (2,0) node[t, label=90:$v_6$] (v6) {a};
		\draw[edge] (v2) -- (v4) node [edgeLabel] {$c$};
		\draw[edge] (v4) -- (v6) node [edgeLabel] {$c$};
		\end{tikzpicture}
	\]
\end{example}

%TODO: Church-Rosser theorem??

%%%==================================================================%%%
%%%%%%%%%%%%%%%%%%%% TRIPLE GRAPH GRAMMARS %%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%==================================================================%%%
\subsection{Triple Graph Grammars}
Building upon the concepts of graphs and graph grammars, we present, in the following, our understanding over triple graphs and triple graph grammars (TGG), supported by the TGG specification from \cite{schurr1994specification}.

%%%%%% Syntax %%%%%%

\begin{definition}
	A directed labeled triple graph $TG = G_s \ms{m_s} G_c \mt{m_t} G_t$ over $\Sigma$ consists of three disjoint directed labeled graphs over $\Sigma$ (see \ref{def:graph}), respectively, the source graph $G_s$, the correspondence graph $G_c$ and the target graph $G_t$, together with two bijective partial morphisms (see \ref{def:morphism}) $m_s: V_{G_c} \pto V_{G_s}$ and $m_t : V_{G_c} \pto G_{G_t}$, called source and target morphisms, respectively. Directed labeled triple graphs are often referred to simply as triple graphs and we might omit the morphisms' names in the notation. Moreover, we denote the set of all triple graphs over $\Sigma$ as $\alltgraphs{\Sigma}$. We might refer to all vertices of $TG$ by $V_{TG}:= V_s \cup V_c \cup V_t$, all edges by $E_{TG}:= E_s \cup E_c \cup E_t$ and the complete labeling function by $\phi_{TG}:= \phi_{G_s} \cup \phi_{G_c} \cup \phi_{G_t}$.
	Moreover, we define the special empty triple graph as $\emptyTG := E \ms{m_s} E \mt{m_t} E$ with $E = (\emptyset, \emptyset, \emptyset)$ and $m_s = m_t = \emptyset$.
\end{definition}

\begin{definition}
	%TODO: Maybe make the rightarrows clearer
	A triple isomorphism of directed labeled triple graphs $G = (G_s \ms{g_s} G_c \mt{g_t} G_t)$ and $H = (H_s \ms{h_s} H_c \mt{h_t} H_t)$ is a bijective mapping $m: V_G \to V_H$ that maintains the connections between vertices as well as their labels and the source and target morphisms, that is, $(v,l,w) \in E_G$ if, and only if, $(m(v),l,m(w)) \in E_H$ and $\phi_G(v) = \phi_H(m(v))$ and $v \in G_c$ if, and only if, $v \in \dom g_s \rightarrow m(g_s(v)) = h_s(m(v))$ and $v \in \dom g_t \rightarrow m(g_t(v)) = h_t(m(v))$. In this case, we write $G \isomorph H$, and we denote the equivalence class of all triple graphs isomorphic to G also by $[G]$.
\end{definition}

\begin{definition}
	A $\Gamma\text{-boundary}$ triple graph $TG = G_s \ms{} G_c \mt{} G_t$ is such that $G_s$, $G_c$ and $G_t$ are $\Gamma\text{-boundary}$ graphs.
\end{definition}

%TODO: Make sure introduction says something about triple graphs
As stated before, triple graphs are for us a good tool to express relations between the vertices of two graphs. In the context of model transformation, where graphs represent models, a triple graph holds, for example, a source model and a target model generated from the source, together with the relationship between their vertices. We also advise that in literature, TGG are often modeled as typed graphs, but we judge that for our circumstance labeled graphs fit better and we are convinced that such divergence does not threat the validity of our approach.

Below we start introducing the standard definition of TGG of the current research's literature. As the reader should notice, this definition of TGG does not fit our needs optimally, because it defines a context-sensitive graph grammar whilst we wish a context-free graph grammar to use together with the NCE graph grammar formalism. Hence, after presenting the conventional TGG definition, we refine it to create a NCE TGG, that fits our context best.

\begin{definition}
	\label{def:stgg}
	A triple graph grammar $TGG = (\Sigma, \Delta \subseteq \Sigma, S \in \Sigma, P)$ consists of, analogously to graph grammars (see Definition \ref{def:gg}), an alphabet $\Sigma$, a set of terminal symbols $\Delta$, a start symbol $S$ and a set of production rules $P$ of the form $L \pro R$ with $L = L_s \ms{} L_c \mt{} L_t$ and $R = R_s \ms{} R_c \mt{} R_t$ and $L \subseteq R.$
\end{definition}

\begin{definition}
	\label{def:tgg}
	A triple graph grammar with neighborhood-controlled embedding (NCE TGG) $TGG = (\Sigma, \Delta \subseteq \Sigma, S \in \Sigma, P)$ consists of, an alphabet $\Sigma$, a set of terminal symbols $\Delta$ (also define $\Gamma := \Sigma \setminus \Delta$), a start symbol $S$ and a set of production rules $P$ of the form $(A \pro (R_s \ms{} R_c \mt{} R_t), \omega_s, \omega_t)$ with $A \in \Gamma$ being the left-hand side, $(R_s \ms{} R_c \mt{} R_t) \in \alltgraphs{\Sigma}$ the right-hand side and $\omega_s : V_{R_s} \pto 2^{\Sigma \times \Sigma}$ and $\omega_t : V_{R_t} \pto 2^{\Sigma \times \Sigma}$ the partial embedding functions from the right-hand side's vertices to pairs of edge and vertex labels. We might refer to the complete embedding function by $\omega:= \omega_s \cup \omega_t$.
	
	For convenience, define the start triple graph of $TGG$ as $\startTG{TGG} := Z_s \ms{m_s} Z_c \mt{m_t} Z_t$ where $Z_s = (\{s_0\},\emptyset,\{s_0 \mapsto S\})$, $Z_c = (\{c_0\},\emptyset,\{c_0 \mapsto S\})$, $Z_t = (\{t_0\},\emptyset,\{t_0 \mapsto S\})$, $m_s = \{c_0 \mapsto s_0 \}$ and $m_t = \{c_0 \mapsto t_0 \}$. Production rules of triple graph grammars are also called triple rules.
	
	%TODO: discuss empty productions(?)
\end{definition}

\begin{definition}
	A boundary triple graph grammar with neighborhood-controlled embedding (BNCE TGG) is such that non-terminal vertices of the right-hand sides of rules are not neighbors. That is, the triple graph grammar $TGG$ is boundary if, and only if,all its rules' right-hand sides are $\Gamma\text{-boundary}$ triple graphs.
\end{definition}

The most important difference between the traditional TGG and the NCE TGG, is that the former allows any triple graph to occur in the left-hand sides, whereas the latter only one symbol. In addition to that, traditional TGG requires that the whole left hand side occur also in the right-hand side, that is to say, the rules are monotonic crescent. Therewith, embedding is not an issue, because an occurrence of the left-hand side is not effectively replaced by the right-hand side, instead, only new vertices are added. On the other hand, NCE TGG has to deal with embedding through the embedding function.

%%%%%% Semantics %%%%%%
In the following, the semantics for NCE TGG is presented analogously to the semantics for NCE graph grammars.

\begin{definition}
	%TODO: Maybe define dstep more formally
	\label{def:tgg_dstep}
	Let $TGG = (\Sigma, \Delta, S, P)$ be a NCE TGG and $G = G_s \ms{g_s} G_c \mt{g_t} G_t$ and $H = H_s \ms{h_s} H_c \mt{h_t} H_t$ be two triple graphs over $\Sigma$ disjoint from any right-hand side from $P$, $G$ concretely derives in one step into $H$ with rule $r$ and distinct vertices $v_s, v_c, v_t$, we write $G \tcderiv{r}{v_s,v_c,v_t}{TGG} H$ if, and only if, the following holds:
	\begin{align*}
		r & = (A \pro (R_s \ms{r_s} R_c \mt{r_t} R_t), \omega_s, \omega_t) \in P \text{ and } \\
		A & = \phi_{G_s}(v_s) = \phi_{G_c}(v_c) = \phi_{G_t}(v_t) \text{ and}\\
		V_{H_s}  & = (V_{G_s} \setminus \{v_s\}) \cup V_{R_s} \text{ and}\\
		V_{H_c}  & = (V_{G_c} \setminus \{v_c\}) \cup V_{R_c} \text{ and}\\
		V_{H_t}  & = (V_{G_t} \setminus \{v_t\}) \cup V_{R_t} \text{ and}\\
		E_{H_s} & = (E_{G_s} \setminus (\{(v_s,l,w) \st (v_s,l,w) \in E_{G_s}\} \cup \{(w,l,v_s) \st (w,l,v_s) \in E_{G_s}\})) \\
		& \cup E_{R_s} \\
		& \cup \{(w,l,t) \st (w,l,v_s) \in E_{G_s} \land (l,\phi_{G_s}(w)) \in \omega_{s}(t)\} \\
		& \cup \{(t,l,w) \st (v_s,l,w) \in E_{G_s} \land (l,\phi_{G_s}(w)) \in \omega_{s}(t)\} \text{ and} \\
		E_{H_c} & = (E_{G_c} \setminus (\{(v_c,l,w) \st (v_c,l,w) \in E_{G_c}\} \cup \{(w,l,v_c) \st (w,l,v_c) \in E_{G_c}\})) \\
		& \cup E_{R_c} \text{ and} \\
		E_{H_t} & = (E_{G_t} \setminus (\{(v_t,l,w) \st (v_t,l,w) \in E_{G_t}\} \cup \{(w,l,v_t) \st (w,l,v_t) \in E_{G_t}\})) \\
		& \cup E_{R_t} \\
		& \cup \{(w,l,t) \st (w,l,v_t) \in E_{G_t} \land (l,\phi_{G_t}(w)) \in \omega_{t}(t)\} \\
		& \cup \{(t,l,w) \st (v_t,l,w) \in E_{G_t} \land (l,\phi_{G_t}(w)) \in \omega_{t}(t)\} \text{ and} \\
		h_s		& = (g_s \setminus \{(v_c,x) \st x \in V_{G_s}\}) \cup r_s  \\
		h_t		& = (g_t \setminus \{(v_c,x) \st x \in V_{G_t}\}) \cup r_t  \\
		\phi_{H_s} & = (\phi_{G_s} \setminus \{(v_s,x) \st x \in \Sigma\}) \cup \phi_{R_s} \text{ and}\\
		\phi_{H_c} & = (\phi_{G_c} \setminus \{(v_c,x) \st x \in \Sigma\}) \cup \phi_{R_c} \text{ and}\\
		\phi_{H_t} & = (\phi_{G_t} \setminus \{(v_t,x) \st x \in \Sigma\}) \cup \phi_{R_t}\\
	\end{align*}
	Notice that, without loss of generality, we set $\omega(t) = \emptyset$ for all vertices $t$ without an image defined in $\omega$.
	
	Analogously to graph grammars, if $G \cderiv{r}{v_s,v_c,v_t}{TGG} H$ and $H' \in [H]$, then $G \tderiv{r}{v_s,v_c,v_t}{TGG} H'$, moreover the reflexive transitive closure of $\tderiv{}{}{}$ is denoted by $\tderivtr{}$ and we call these relations by the same names as before, namely, derivation in one step and derivation. We might also omit identifiers.
\end{definition}

A concrete derivation of a triple graph $G = G_s \ms{g_s} G_c \mt{g_t} G_t$ can de informally understood as concrete derivations (see \ref{def:gg_dstep}) of $G_s$, $G_c$ and $G_t$ according to the right-hand sides $R_s$, $R_c$ and $R_t$. The only remark is the absence of an embedding mechanism for the correspondence graph, which edges are not important for our application. Nevertheless, the addition of such a mechanism for the correspondence graph should not be a problem if it is desired.

\begin{definition}
	A derivation $D$ in the triple graph grammar $TGG$ is a non-empty sequence of derivation steps
	\[ 
	D = (G_0 \tderiv{r_0}{s_0,c_0,t_0}{} G_1 \tderiv{r_1}{s_1,c_1,t_1}{} G_2 \tderiv{r_2}{s_2,c_2,t_2}{} \dots \tderiv{r_{n-1}}{s_{n-1},c_{n-1},t_{n-1}}{} G_n)
	\]
\end{definition}

\begin{definition}
	\label{def:tlanguage}
	The language $L(TGG)$ generated by the triple grammar $TGG$ is the set of all triple graphs containing only terminal vertices derived from the start triple graph $\startTG{TGG}$, that is
	\[
	L(TGG) = \{H \text{ is a triple graph over } \Delta \text{ and } \startTG{TGG} \tderivtr{} H\}
	\]
\end{definition}

Our concrete syntax for NCE TGG is similar to the one for NCE graph grammars and is presented below by means of the Example \ref{ex:pseudocode2controlflow}. The only difference is at the right-hand sides, that include the morphisms between the correspondence graph and source and target graphs depicted with dashed lines.

%Concrete syntax and examples (Pseudocode 2 Control Flow [sourcecode2controlflow])
\begin{example}{Pseudocode to Controlflow.}
	\label{ex:pseudocode2controlflow}
	%TODO: So far, it should be let clear what TGG are used for (introduction)
	This example illustrates the definition of a BNCE TGG that characterizes the language of all $Pseudocode$ graphs together with their respective $Controlflow$ graphs. A $Pseudocode$ graph is an abstract representation of a program written in a pseudo-code where vertices refer to \textit{actions}, \textit{ifs} or \textit{whiles} and edges connect these items together according to how they appear in the program. A $Controlflow$ graph is a more abstract representation of a program, where vertices can only be either a \textit{command} or a \textit{branch}.
	
	Consider, for instance, the program $main$, written in a pseudo-code, and the triple graph $TG$ in Figure \ref{fig:p2c-tg}. The triple graph $TG$ consists of the $Pseudocode$ graph of $main$ connected to the $Controlflow$ graph of the same program through the correspondence graph in the middle of them. In such graph, the vertex labels of the $Pseudocode$ graph $p, i, a, w$ correspond to the concepts of \textit{program}, \textit{if}, \textit{action} and \textit{while}, respectively. The edge label $f$ is given to the edge from the vertex $p$ to the program's first statement, $x$ stands for \textit{next} and indicates that a statement is followed by another statement, $p$ and $n$ stand for \textit{positive} and \textit{negative} and indicate which assignments correspond to the positive of negative case of the \textit{if}'s evaluation, finally $l$ stands for \textit{last} and indicates the last action of a loop. In the $Controlflow$ graph, the vertex labels $g, b, c$ stand for the concepts of \textit{graph}, \textit{branch} and \textit{command}, respectively. The edge label $r$ is given to the edge from the vertex $g$ to the first program's statement, $x, p$ and $n$ mean, analogous to the former graph, \textit{next}, \textit{positive} and \textit{negative}. In the correspondence graph, the labels $pg, ib, ac, wb$ serve to indicate which labels in the source and target graphs are being connected through the triple graph's morphism.
	%TODO: advise that command are not stuffed with further information that actually characterizes them. But it could be done with a future work on attributed graphs
	
	\input{examples/pseudocode2controlflow-tg}
	
	The main difference between the two graphs is the absence of the $w$ label in the $Controlflow$ graph, what makes it encode loops through the combination of $b$-labeled vertices and $x$-labeled edges.
	
	The TGG that specifies the relation between these two types of graphs is $TGG = (\{S, A, p, a, i, w, g, b, c, f, x, n, l, r, pg, ac, ib, wb\}, \{p, a, i, w, g, b, c, f, x,$ $ n, l, r, pg, ac, ib, wb\}, S, P)$, where $P = \{r_i \st 0 \le i \le 5\}$ is denoted by\\
	\input{examples/pseudocode2controlflow-tgg}
	
	\noindent
	with $\sigma_0 = \emptyset$, $\sigma_1(s_{11}) = \sigma_2(s_{21}) = \sigma_3(s_{31}) = \sigma_4(s_{41}) =\sigma_5(s_{51}) = \{ (f,p), (x,a), $ $(x,i), (x,w), (p,i), (n,i), (l,w), (f,w) \}$ and $\tau_1(t_{11}) = \tau_2(t_{21}) = \tau_3(t_{31}) = \tau_4(t_{41}) $ $= \tau_5(t_{51}) = \{ (r,g), (x,c), (x,b), (p,b), (n,b)\}$ being the complete definition of the source and target embedding functions of the rules $r_0$ to $r_5$, respectively.
	
	The rule $r_0$ relates programs to graphs, $r_1$ actions to commands, $r_2$ ifs to branches, $r_3$ empty whiles to simple branches, $r_4$ filled whiles to filled loops with branches, $r_5$ whiles with one action to loops with branches with one command and, finally, $r_6$ produces an empty graph from a symbol $A$, what allows any derivation in the grammar to finish.
	
	The aforementioned triple graph $TG$ is in $L(TGG)$, because the derivation
	$
	\startTG{TGG} \tderiv{r_0}{}{} G_1 \tderiv{r_2}{}{} G_2 \tderiv{r_6}{}{} G_3 \tderiv{r_1}{}{} G_4 \tderiv{r_6}{}{} G_5 \tderiv{r_1}{}{} G_6 \tderiv{r_4}{}{} G_7 \tderiv{r_1}{}{} G_8 \tderiv{r_6}{}{} G_9 \tderiv{r_1}{}{} G_{10} \tderiv{r_6}{}{} TG
	$
	is a derivation in TGG with appropriate $G_i$ for $1 \le i \le 10$.
\end{example}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% PARSING %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Parsing of Graphs with BNCE Graph Grammars}
In the last section we cleared how the concepts of graphs and languages fit together. In this section we are interested in the problem of deciding, given a BNCE graph grammar $GG$ and a graph $G$, whether $G \in L(GG)$. This is sometimes called the \textit{membership} problem and can be solved through a recognizer algorithm that always finishes answering yes if and only if $G \in L(GG)$ and no otherwise. A slight extension of this problem is the \textit{parsing} problem, which consists of deciding if $G \in L(GG)$ and finding a derivation $\startG{GG} \derivtr{} G$.

%TODO: The practical use of it: model checking... model validation

The parsing algorithm posed in this section is an imperative view of the method proposed by ()%TODO: cite 27
, which is basically a version fro graphs of the well-known CYK (Cocke-Young-Kassami) algorithm for parsing of strings with a context-free (string) grammar. Preliminarily to the actual algorithm's presentation, we introduce some necessary concepts that are used by it. The first of them is the neighborhood preserving normal form.

\begin{definition}
	\label{def:np}
	A BNCE graph grammar $GG = (\Sigma, \Delta, S, P)$ is neighborhood preserving (NP), if and only if, the embedding of each rule with left-hand side $A$ is greater or equal than the context of each $A$-labeled vertex in the grammar. That is, let 
	\[\cont{(A \pro R,\omega)}{v} =\{(l,\phi_{R}(w)) \st (v,l,w) \in E_R \text { or } (w,l,v) \in E_R \} \cup \omega(v) \]
	be the context of $v$ in the rule $(A \pro R,\omega)$ and
	\[\scont{GG}{A} = \bigcup_{(B \pro Q,\zeta) \in P, v \in V_Q, \phi_Q(v) = A} \cont{B \pro Q,\zeta}{v} \] 
	be the context of the symbol $A$ in the grammar $GG$, then $GG$ is a NP BNCE graph grammar, if and only if,
	\[ \forall r = (A \pro R,\omega) \in P \. \scont{GG}{A} \subseteq \bigcup_{v \ in V_R} \omega(v) \]
\end{definition}

The NP property is important to the correctness of the parsing algorithm. Furthermore, it is guaranteed that any BNCE graph grammar can be transformed in an equivalent NP BNCE graph grammar in polynomial time. More details in () %TODO: cite 27

The next paragraphs present zone vertices and zone graphs, that are our understanding of the concepts also from %TODO: cite 27

\begin{definition}
	\label{def:zv}
	A zone vertex $h$ of a graph $G$ over $\Sigma$ is a pair $(\sigma \in \Sigma, U \subseteq V_G)$, that is, a symbol from $\Sigma$ and a subset of the vertices of $G$.
	
	A zone vertex can be understood as a contraction of a subgraph of $G$ defined by the vertices $U$ into one vertex with symbol $\sigma$.
\end{definition}

\begin{definition}
	\label{def:z}
	Let $H = \{(\sigma_0,U_0),(\sigma_1,U_1),\dots,(\sigma_m,U_m)\}$ be a set of zone vertices of a graph $G$ over $\Sigma$ with disjoint vertices (i.e. $U_i \cap U_j = \emptyset$ for all $0 \leq i,j \leq m \text{ and } i \neq j$) and $V(H) = \bigcup_{0 \leq i \leq m}{U_i}$. A zone graph $Z(H)$ for $H$ is $Z(H) = (V, E, \phi)$ with $V$ being the zone vertices, $E \subseteq V \times \Sigma \times V$ the edges between zone vertices and $\phi: V \to \Sigma$ the labeling function, determined by
	\begin{align*}
		V & = H \cup \{(\phi_G(x),\{x\}) \st x \in \neigh{G}(V(H)) \}\\
		E & = \{((\sigma,U),l,(\eta,T)) \st (\sigma,U),(\eta,T) \in V \text{ and } U \neq T \text{ and } \\
		& (u,l,t) \in E_G \text{ and } u \in U \text{ and } t \in T\} \\
		\phi & = \{(\sigma,U) \mapsto \sigma  \st (\sigma,U,W) \in V\}
	\end{align*}
	The zone graph $Z(H)$ can be intuitively understood as a subgraph of $G$, where each zone vertex in $V_{Z(H)}$ is either a $(\sigma_i,U_i)$ of $H$, which is a contraction of the vertices $U_i$ of $G$, or a $(\phi_G(x),\{x\})$, which stems from $x$ being a neighbor of some vertex in $V_i$.
	
	For convenience, define $Y(H)$ as the subgraph of $Z(H)$ induced by H.
	%TODO: maybe write more about induction
	%TODO: comment about information duplication of labels
\end{definition}

\begin{definition}
	Let $h$ be a zone vertex, $r$ a production rule and $X$ a (potentially empty) set of parsing trees, $\ptree{h}{r}{X}$ is a parsing tree, whereby $h$ is called the root node and $X$ the children and $r$ is optional. $D(pt)$ gives a derivation for the parsing tree $pt$, which can be calculated by performing a depth-first walk on $pt$, starting from its root node, producing as result a sequence of derivation steps that correspond to each visited node and its respective rule. Additionally, a set of parsing trees is called a parsing forest.
	%TODO: Write D(pt) more formally. Explain the assembly of the effective derivation out of the sequence of sub derivation steps of the parsing tree nodes and explain how the isomorphims looks like. Because at the end, the derivation goes to a G', with G' in [G]
\end{definition}

Finally, the Algorithm \ref{alg:parse} displays the parsing algorithm of graphs with a NP BNCE graph grammar. Informally, the procedure follows a bottom-up strategy that tries to find production rules in $GG$ that generate zone graphs of $G$ until it finds a rule that generates a zone graph containing all vertices of $G$ and finishes answering yes and returning a valid derivation for $G$ or it exhausts all the possibilities and finishes answering no.

\begin{algorithm}[!h]
	\caption{Parsing Algorithm for NP BNCE Graph Grammars}
	\begin{algorithmic}[!ht]
		\Require $GG \text{ is a valid NP BNCE graph grammar}$
		\Require $G \text{ is a valid graph over } \Delta$ \Comment{$G$ has terminal vertices only}
		\Function{$parse$}{$GG=(\Sigma, \Delta, S, P), G=(V_G,E_G,\phi_G)$}{$:Derivation$}
			\State $bup \gets \{(\phi_G(x),\{x\}) \st x \in V_G\}$ \Comment{start $bup$ with trivial zone vertices}
			\State $pf \gets \{ \ptree{b}{}{\emptyset} \st b \in bup \}$ \Comment{initialize parsing forest}
			\Repeat
				\State $h \gets \text{\Select } \{X \subseteq bup \st\text{for all } U_i, U_j \in X \text{ with } i \neq j \. U_i \cap U_j = \emptyset \}$
				\ForAll{$d \in \Gamma$} \Comment{for each non-terminal symbol}
					\State $r \gets \text{any } \{(d \pro R,\omega) \in P \st R \isomorph Y(h) \}$
					\State $l \gets (d,V(h))$
					\If{$Z(\{l\}) \deriv{r}{l}{} Z(h)$}
						\State $bup \gets bup \cup \{l\}$ \Comment{new zone vertex found}
						\State $pf \gets pf \cup \{ \ptree{l}{r}{\{\ptree{z}{y}{X} \st \ptree{z}{y}{X} \in pf, z \in h \}} \}$
					\EndIf
				\EndFor
			\Until{$(S, V_G) \in bup$} \Comment{if found the root, stop}
			\State \Return $(S, V_G) \in bup \? \Just D(\ptree{(S,V_G)}{y}{X} \in pf) \: \Nothing $
		\EndFunction
		\Ensure $return \text{ is either } \Nothing \text{ or of the form } \Just \startG{GG} \derivtr{} G$
	\end{algorithmic}
	\label{alg:parse}
\end{algorithm}

The variable $bup$ ($bup$ stands for bottom-up parsing set, see ())%TODO: cite
is started with the trivial zone vertices of $G$, each containing only one vertex of $V_G$, and grows iteratively with bigger zone vertices that can be inferred using the grammar's rules and the elements of $bup$.

The variable $h$ stands for handle and is any subset from $bup$ chosen to be evaluated for the search of new zone vertices to insert in $bup$. The procedure $\Select$ gives one yet not chosen handle or an empty set and cares for the termination of the execution. Then, for the chosen $h$, rules $r$ with left-hand side $d$ and right-hand side isomorphic to $Y(h)$ that produce $Z(h)$ from $Z(\{l\})$ are searched. If any is found, then $l = (d,V(h))$ is inserted into $bup$. This basically means that it found a zone vertex that encompasses the vertices $V(h)$ (a possibly bigger subset than other elements in $bup$), from which, through the application of a sequence of rules, we can produce the subgraph of G induced by $V(h)$. This information is saved in the parsing forest $pf$ in form of a parsing tree with node $l$ and children $\ptree{z}{y}{X}$, already in the parsing forest $pf$, for all $z \in h$.

If, in some iteration the zone vertex $(S, V_G)$ is inferred, then it means that the whole graph $G$ can be produced through the application of a derivation starting from the start graph $\startG{GG}$ and thus $G \in L(GG)$. This derivation is, namely, the result of a depth-first walk in the parsing tree whose root is $(S, V_G)$. If, otherwise, all possibilities for $h$ were exhausted without inferring such zone vertex, then $\Nothing$ is returned, what means that $G$ cannot de parsed with $GG$ and therefore $G \notin L(GG)$.

%TODO: Talk about the empty productions, that are allowed
%TODO: Talk about the isomorphism in the reduction test

%TODO: We beleieve this imperative view is also a contribution of our work

%TODO: Comment on correctness and completeness
%TODO: Comment on termination and spatial and time complexity
%TODO: Nevertheless, the grammar's ambiguity does not compromise the correctness of our algorithms presented in the following.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%% MODEL TRANSFORMATION %%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\section{Model Transformation with BNCE Triple Graph Grammars}
As already introduced, TGG can be used to characterize languages of triple graphs holding correctly transformed models. That is, one can interpret a TGG as the description of the correctly-transformed relation between two sets of models $\mathcal{S}$ and $\mathcal{T}$, where two models $G \in \mathcal{S}$ and $T \in \mathcal{T}$ are in the relation if and only if $G$ and $T$ are respectively, source and target graphs of any triple graph of the language $L(TGG)$. That being said, we are interested in this section on defining a model transformation algorithm that interprets a BNCE TGG $TGG$ to transform a source model $G$ into one of its correspondent target models $T$ according to the correctly-transformed relation defined by $TGG$.

For that end, let $TGG = (\Sigma = \Sigma_s \cup \Sigma_t, \Delta, S, P)$ be a triple graph grammar defining the correctly-transformed relation between two arbitrary sets of graphs $\mathcal{S}$ over $\Sigma_s$ and $\mathcal{T}$ over $\Sigma_t$. And let $G \in \mathcal{S}$ be a source graph. We want to find a target graph $T \in \mathcal{T}$ such that $G \ms{} C \mt{} T \in L(TGG)$. To put in words, we wish to find a triple graph holding $G$ and $T$ that is in the language of all correctly transformed models. Hence, the model transformation problem is reduced--- according to the definition of triple graph language (see Definition \ref{def:tlanguage})--- to the problem of finding a derivation $\startTG{TGG} \tderivtr{TGG} G \ms{} C \mt{} T$.

Our strategy to solve this problem is, first, to get a derivation for $G$ with the source part of $TGG$ and, then, construct the derivation $\startTG{TGG} \tderivtr{TGG} G \ms{} C \mt{} T$. For this purpose, consider the definitions of the $\source$ and $\target$ functions, that extract the source and the target part of production rules.

\begin{definition}
	\label{def:source}
	Let $r = (A \pro (G_s \ms{} G_c \mt{} G_t), \omega_s, \omega_t)$ be a production rule of a triple graph grammar, $\source(r) = (A \pro G_s,\omega_s)$ gives the source part of $r$ and $\target(r) = (A \pro G_t,\omega_t)$ gives the target part. Moreover, $\source^{-1}((A \pro G_s,\omega_s)) = r$ and $\target^{-1}((A \pro G_t,\omega_t)) = r$ are the inverse of these functions.
\end{definition}

\begin{definition}
	\label{def:Source}
	Let $TGG = (\Sigma, \Delta, S, P)$ be a triple graph grammar, $\Source(TGG) = (\Sigma, \Delta, S, \source(P))$ gives the source grammar of $TGG$ and $\Target(TGG) = (\Sigma, \Delta, S, \target(P))$ gives the target grammar of $TGG$.
\end{definition}

Furthermore, consider the definition of the non-terminal consistent (NTC) property of TGG, which assures that non-terminal vertices of the correspondent graph are connected to vertices with the same label in the source and target graphs.

%TODO: I guess the second item can be removed. morphism is bijective by definition
\begin{definition}
	A triple graph grammar $TGG = (\Sigma, \Delta, S, P)$ is non-terminal consistent (NTC) if and only if, for all rules $(A \pro (G_s \ms{m_s} G_c \mt{m_t} G_t), \omega_s, \omega_t) \in P$, the following holds:
	\begin{enumerate}
		\item $\forall c \in V_{G_c} \. \text{if } \phi_{G_c}(c) \in \Gamma \text{ then } \phi_{G_c}(c) = \phi_{G_s}(m_s(c)) = \phi_{G_t}(m_t(c))$ and
		\item For the sets $N_s = \{v \st \phi_{G_s}(v) \in \Gamma\}$ and $N_t = \{v \st \phi_{G_t}(v) \in \Gamma\}$, the range-restricted functions $(m_s \rrestr N_s)$ and $(m_t \rrestr N_t)$ are bijective.
	\end{enumerate}
\end{definition}

Finally, the following result gives us an equivalence between a derivation in $TGG$ and a derivation in its source grammar $S(TGG)$, which allows us to construct our goal derivation of $G \ms{} C \mt{} T$ in $TGG$ using the derivation of $G$ in $S(TGG)$.

%TODO: Review theorem with new formulation of the ms mt morphisms, bijective bu not total
\begin{theorem}
	\label{thm:one_d_enough}
	Let $TGG = (\Sigma, \Delta, S, P)$ be a NTC TGG and $k \ge 1$, \\
	$D = \startTG{TGG} \tderiv{r_0}{s_0,c_0,t_0}{} G^1 \tderiv{r_1}{s_1,c_1,t_1}{} \dots \tderiv{r_{k-1}}{s_{k-1},c_{k-1},t_{k-1}}{} G^k$ is a derivation in $TGG$ if, and only if, $\overline{D} = \startG{S(TGG)} \deriv{s(r_0)}{s_0}{} G^1_s \deriv{s(r_1)}{s_1}{} \dots \deriv{s(r_{k-1})}{s_{k-1}}{} G^k_s$ is a derivation in $S(TGG)$.
\end{theorem}
\begin{proof}
	%TODO: Maybe referencing to each condition from the gg_dstep abd tgg_dstep definitions
	We want to show that if $D$ is a derivation in $TGG = (\Sigma, \Delta, S, P)$, then $\overline{D}$ is a derivation in $SG := S(TGG) = (\Sigma, \Delta, S, SP)$, and vice-versa. We prove it by induction in the following.
	
	First, for the induction base, since, $\startTG{TGG} \tderiv{r_0}{s_0,c_0,t_0}{TGG} G^1$, then expanding $\startTG{TGG}$ and $G^1$, we have
	\begin{align*}
		& Z_s \ms{} Z_c \mt{} Z_t \tderiv{r_0}{s_0,c_0,t_0}{TGG} G^1_s \ms{} G^1_c \mt{} G^1_t \text{, then, by Definition \ref{def:tgg_dstep},}\\
		& r_0 = (S \pro (R_s \ms{} R_c \mt{} R_t), \omega_s, \omega_t) \in P \text{ and, by Definition \ref{def:source},}\\
		& \source(r_0) = (S \pro R_s, \omega_s) \in SP
	\end{align*}
	
	Hence, using it plus the configuration of $\phi_{Z_s}(s_0)$, $V_{G^1_s}$, $E_{G^1_s}$ and $\phi_{G^1_s}$ and the equality $Z_s = \startG{SG}$, we have, by Definition \ref{def:gg_dstep}, $\startG{SG} \deriv{\source(r_0)}{s_0}{SG} G^1_s$.
	
	In the other direction, we choose $c_0, t_0$ from the definition of $\startTG{TGG}$, with $\phi_{Z_c}(c_0) = S$ and  $\phi_{Z_t}(t_0) = S$. In this case, since,
	\begin{align*}
		& \startG{SG} \deriv{s(r_0)}{s_0}{SG} G^1_s \text{, then by Definition \ref{def:gg_dstep},}\\
		& \source(r_0) = (S \pro R_s, \omega_s) \in SP \text{ and, using the bijectivity of $\source$, we get}\\
		& r_0 = \source^{-1}(s(r_0)) = (S \pro (R_s \ms{} R_c \mt{} R_t), \omega_s, \omega_t) \in P
	\end{align*}
	
	Hence, using it plus the configuration of $\phi_{\startG{SG}}(s_0)$, $V_{G^1_s}$, $E_{G^1_s}$ and $\phi_{G^1_s}$, the equality $Z_s = \startG{SG}$ and constructing $V_{G^1_c}$, $V_{G^1_t}$, $E_{G^1_c}$, $E_{G^1_t}$, $\phi_{G^1_c}$, $\phi_{G^1_t}$ from $Z_c$ and $Z_t$ according to the Definition \ref{def:tgg_dstep} $\startTG{TGG} \tderiv{r_0}{s_0,c_0,t_0}{TGG} G^1_s \ms{} G^1_c \mt{} G^1_t$.
	
	Now, for the induction step, we want to show that if $\startTG{TGG} \tderivtr{TGG} G^i$ $\tderiv{r_{i}}{s_{i},c_{i},t_{i}}{TGG} G^{i+1}$ is a derivation in $TGG$, then $\startG{SG} \derivtr{SG} G^i_s \deriv{s(r_{i})}{s_{i}}{SG} G^{i+1}_s$ is a derivation in $SG$ and vice-versa, provided that the equivalence holds for the first $i$ steps, so we just have to show it for the step $i+1$.
	
	So, since, $G^i \tderiv{r_{i}}{s_{i},c_{i},t_{i}}{TGG} G^{i+1}$, that is
	\begin{align*}
		& G^i_s \ms{ms_i} G^i_c \mt{mt_i} G^i_t \tderiv{r_i}{s_i,c_i,t_i}{TGG} G^{i+1}_s \ms{} G^{i+1}_c \mt{} G^{i+1}_t \text{, then, by Definition \ref{def:tgg_dstep},}\\
		& r_i = (S \pro (R_s \ms{} R_c \mt{} R_t), \omega_s, \omega_t) \in P \text{, and by Definition \ref{def:source},}\\
		& \source(r_i) = (S \pro R_s, \omega_s) \in SP
	\end{align*}
	
	Hence, using it plus the configuration of $\phi_{G^i_s}(s_i)$, $V_{G^{i+1}_s}$, $E_{G^{i+1}_s}$ and $\phi_{G^{i+1}_s}$, we have, by Definition \ref{def:gg_dstep}, $G_s^i \deriv{\source(r_i)}{s_i}{SG} G^{i+1}_s$.
	
	In the other direction, we choose, using the bijectivity from the range restricted function $\source$, stemming from the NTC property, $c_i = ms_i^{-1}(s_i), t_i = mt_i(c_i)$. Moreover, since $TGG$ is NTC, and because, by induction hypothesis, $\startTG{TGG} \tderivtr{TGG} G^i$ is a derivation in $TGG$ and $\phi_{G^i_s}(s_i) \in \Gamma$, it is clear that $\phi_{G^i_s}(s_i) = \phi_{G^i_c}(c_i) = \phi_{G^i_t}(t_i)$.
	
	In this case, since
	\begin{align*}
		& G^{i}_s \deriv{s(r_i)}{s_i}{SG} G^{i+1}_s \text{, then, by Definition \ref{def:gg_dstep},}\\
		& \source(r_i) = (A \pro R_s, \omega_s) \in SP \text{ and, using the bijectivity of $\source$, we get }\\
		& r_i = \source^{-1}(s(r_i)) = (A \pro (R_s \ms{} R_c \mt{} R_t), \omega_s, \omega_t) \in P
	\end{align*} 
	
	Hence, using, additionally, the configuration of $\phi_{G^i_s}(s_i)$, $\phi_{G^i_c}(c_i)$, $\phi_{G^i_t}(t_i)$, $V_{G^{i+1}_s}$, $E_{G^{i+1}_s}$ and $\phi_{G^{i+1}_s}$ and constructing $V_{G^{i+1}_c}$, $V_{G^{i+1}_t}$, $E_{G^{i+1}_c}$, $E_{G^{i+1}_t}$, $\phi_{G^{i+1}_c}$, $\phi_{G^{i+1}_t}$ from $G^i_c$ and $G^i_t$ according to the Definition \ref{def:tgg_dstep}, we have 
	\begin{equation*}
		G^i_s \ms{} G^i_c \mt{} G^i_t \tderiv{r_i}{s_i,c_i,t_i}{TGG} G^{i+1}_s \ms{} G^{i+1}_c \mt{} G^{i+1}_t
	\end{equation*}
	
	This finishes the proof.\qed
\end{proof}

Therefore, by Theorem \ref{thm:one_d_enough}, the problem of finding a derivation $D = \startTG{TGG} \tderivtr{TGG} G \ms{} C \mt{} T$ is reduced to finding a derivation $\overline{D} = \startG{S(TGG)} \deriv{}{}{S(TGG)} G$, what can be done with the already presented parsing algorithm \ref{alg:parse}. The final construction of the triple graph $G \ms{} C \mt{} T$ becomes then just a matter of creating $D$ out of $\overline{D}$.

%TODO: Comment about the backward case, should be trivial

The complete transformation procedure is presented in the Algorithm \ref{alg:transform}. Thereby it is required that the TGG be neighborhood preserving (NP), what poses no problem to our procedure, once any TGG can be transformed into the neighborhood preserving normal form. 

%TODO: Maybe talk more about the normalization for TGG

\begin{algorithm}[!h]
	\caption{Transformation Algorithm for NP NTC BNCE TGG}
	\begin{algorithmic}[!ht]
		\Require $TGG \text{ is a valid NP NTC BNCE triple graph grammar}$
		\Require $G \text{ is a valid graph over } \Sigma$
		\Function{$transform$}{$TGG=(\Sigma, \Delta, S, P), G=(V_G,E_G,\phi_G)$}{$:Graph$}
		\State $SG \gets S(TGG)$ \Comment{see \ref{def:source}}
		\State $\overline{D} \gets parse(SG,G)$ \Comment{use algorithm \ref{alg:parse}}
		\If{$\overline{D} = \startG{SG} \derivtr{SG} G$} \Comment{if parsed successfully}
		\State from $\overline{D}$ construct $D = \startTG{TGG} \tderivtr{TGG} G \ms{} C \mt{} T$
		\State \Return {$\Just T$}
		\Else
		\State \Return {$\Nothing$} \Comment{no $T$ satisfies $(G \ms{} C \mt{} T) \in L(TGG)$}
		\EndIf
		\EndFunction 
		\Ensure $return \text{ is either } \Nothing \text{ or } \Just T \text{, such that } (G \ms{} C \mt{} T) \in L(TGG)$
	\end{algorithmic}
	\label{alg:transform}
\end{algorithm}

%Incremental and Synchhronization
%TODO: discourse about incremental transformation and synchronization
%TODO: Discuss ambiguiity in the grammar and the non-determinism in the generation of TGs in this case
%TODO: Comment on termination and spatial and time complexity

%TODO: Comment on correctness and completeness in the TGG sense. Analyze empty productions in TGG, critical-pairs, such complicated things

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%% TGG EXTENTION %%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{An Extension of NCE Triple Graph Grammars with Application Conditions}
The NCE graph grammar formalism from \cite{janssens1982graph}, presented in the previous sections, can define with very few rules the languages of several classes of labeled graphs, including trees, path graphs, star graphs, control-flow graphs, edgeless graphs, complete graphs, and others. However, it is at least difficult to define the languages of other classes, like the class-diagram graphs, with NCE graph grammars. In this Section, we approach the problem of defining a NCE graph grammar for these classes of graphs and propose a solution for that by means of an extension of NCE that includes application conditions.

Class diagrams are commonly used to model object-oriented software artifact that are composed of several classes related by associations. For the sake of demonstrating the problem of NCE with class diagrams, consider a simplified view of the class-diagrams graphs, in which a vertex has either label $c$ or $a$, respectively representing a class or an association, and an edge between an association and a class with label $s$ ($t$) signalizes that the class is the source (target) of the association. In Figure \ref{fig:classdiagram-g}, a class-diagram graph with two classes connected by two associations is depicted. An attempt for a NCE graph grammar that would describe the language of all class-diagram graphs is $GG = (\{K,a,c,s,t\}, \{a,c,s,t\}, K, \{r_0, r_1, r_2\})$, with $r_0$, $r_1$, and $r_2$ depicted in Figure \ref{fig:classdiagram-gg} and $\omega_0(c_0) = \omega_1(c_1) = \{(t,a)\}$ and $\omega_0 = \emptyset$ being the complete embedding definition of the rules $r_0$, $r_1$, and $r_2$, respectively.

\begin{figure}[h]
	\begin{subfigure}[t]{0.3\textwidth}
		\centering
		\input{examples/classdiagram-g}
		\caption{A class-diagram graph}
		\label{fig:classdiagram-g}
	\end{subfigure}
	\begin{subfigure}[t]{0.68\textwidth}
		\centering
		\input{examples/classdiagram-gg}
		\caption{The depiction of the rules of $GG$}
		\label{fig:classdiagram-gg}
	\end{subfigure}
	\caption{An example for a class-diagram graph with two classes connected by associations in (a) and the rules $r_0$, $r_1$, and $r_2$ of the graph grammar $GG$ in (b)}
\end{figure}

The problem of the graph grammar $GG$ is that it does not define the complete language of the class-diagram graph. In fact, the graph in Figure \ref{fig:classdiagram-g} is not in $L(GG)$. To see this, consider the following derivation in $GG$, $\startG{GG} \deriv{r_0}{v_0}{}$
\input{examples/classdiagram-der}.

This is the closest we get to deriving the graph in Figure \ref{fig:classdiagram-g} using GG. Thereby, we would like to connect the association $v_2$ to the class $v_1$ but it is not possible, because $v_1$ was not a neighbor of the vertex $K_0$ that preceded $v_2$. Notice that a vertex in any sentential form can only be either connected to vertices that stem from the same rule application or to neighbors of its precedent vertex. In fact, this seems to be a general characteristic for context-free grammars, where the information about elements in the context of the precedents are not available for descendant elements. In order to overcome it, one could potentially elaborate an alternative grammar that defines the desired language completely and concisely, but we believe that such ad-hoc solution would include a bigger number of rules and add complexity to the grammar. With that in mind, we propose in the sequel an extension of the NCE grammar formalism with positive application conditions (PAC) that solves this issue. 

In NCE graph grammars with PAC, rules' right-hand sides are equipped with application conditions in form of special vertices that are produced by derivation steps and removed by so-called resolution steps. A resolution step is responsible for removing such special vertices and moving their adjacent edges to other vertices. This resolution mechanism allows that the vertex $v_2$ from the previous example be connected to $v_1$. 

In order to define the PAC mechanism in detail, the definitions of rule and derivation step are augmented as follows.

\begin{definition}
	A production rule with PAC is of the form $(A \pro R, \omega, U)$ with $A$, $R$ and $\omega$ as described in \ref{def:gg} and $U \subseteq \{v \in V_R \st \phi_R(v) \in \Delta\}$, the set of special vertices, called PAC vertices.
\end{definition}

If a graph grammar has at least one rule with PAC, then we say it is a graph grammar with PAC.

\begin{definition}
	A \textit{concrete derivation step} with PAC in the graph grammar $GG$ is of the form $G \cderivpac{r}{v}{U}{GG} H$ with $G$, $H$, $v$ being as described in Definition \ref{def:gg_dstep}, and $r = (A \pro R, \omega, U)$ being a production rule with PAC. Given that, a \textit{derivation step} is, analogously, of the form $G \derivpac{r}{v}{W}{GG} H'$ with $W = m(U)$ where $m$ is the isomorphism from $H$ and $H'$.
\end{definition}

So far, PAC vertices do not change anything in the behavior of a derivation step and the set $U$ in a derivation step serves just to tag which vertices are PAC in a sentential form. Nevertheless, PAC vertices play an important role on a resolution step, defined below.

\begin{definition}
	Let $GG = (\Sigma, \Delta, S, P)$ be a graph grammar and $G$ a graph over $\Delta$, $G$ resolves into $H$ with the resolution partial function $\rho: V_G \pto V_G$, we write $G \resolv{\rho} H$ and call it a resolution step, if, and only if, the following holds:
	\begin{align*}
		& \forall v \in \dom \rho \. \rho(v) \notin \dom \rho \text{ and } \phi_G(\rho(v)) = \phi_G(v) \text{ and}\\
		V_H & = V_G \setminus \dom \rho \text{ and}\\
		E_H & = (E_G \setminus (\{(u,l,t) \st u \in \dom \rho, (u,l,t) \in E_G\} \\
			&\hspace{3.5em} \cup \{(t,l,u) \st u \in \dom \rho, (t,l,u) \in E_G\}))\\
		    & \cup \{(\rho(u),l,t) \st u \in \dom \rho, (u,l,t) \in E_G\} \\
		    & \cup \{(t,l,\rho(u)) \st u \in \dom \rho, (t,l,u) \in E_G\}
	\end{align*}
\end{definition}

A resolution step can be informally understood as the removal of the PAC vertices of $G$--- that are in the domain of the resolution function $\rho$ ---followed by the redirection of the edges adjacent to the PAC vertices to other vertices of $H$.

For the PAC mechanism to work, it is still necessary to combine derivation and resolution steps to define the language of a grammar with PAC, what we do in the following.

\begin{definition}
	A production $Q$ in a graph grammar with PAC is a sequence of $n$ derivation steps followed by $n$ resolution steps with $n > 0$, as follows:
	\begin{equation*}
		Q = (G_0 \derivpac{r_0}{v_0}{W_0}{} G_1 \derivpac{r_1}{v_1}{W_1}{} \dots \derivpac{r_{n-1}}{v_{n-1}}{W_{n-1}}{} G_n^0 \resolv{\rho_0} G_n^1 \resolv{\rho_1} \dots \resolv{\rho_{n-1}} G_n^n)
	\end{equation*}
	with $s_i$ being a resolution total function $\rho_i : m_i(W_i) \to V_{G_n^i}$ and $m_i : W_i \to V_{G_n^i}$ the mapping from the PAC vertices generated on the derivation step $i$ to their correspondent vertices in $G_n^i$, for all $0 \le i < n$.
\end{definition}

It is clear that, the mapping $m$ of the previous definition exists and is bijective because all PAC vertices are, by definition, terminal and, therefore, are not deleted by derivation steps and, moreover, the images of all $m_i$ are pair-wise disjunct.

\begin{definition}
	The language $L(GG)$ generated by the grammar $GG$ with PAC is
	\begin{equation*}
		L(GG) = \{ H \text{ is a graph over } \Delta \text{ and } \startG{GG} \derivpacn{}{n} H' \resolvn{}{n} H \}
	\end{equation*}
	where $\derivpacn{}{n}$ and $\resolvn{}{n}$ denote a sequence of $n$ derivation steps and $n$ resolution steps, respectively.
\end{definition}

Ultimately, we put forward a NCE graph grammar with PAC whose language is the set of all class-diagram graphs. This grammar is $GG = (\{K, A, a, c, s, t\}, \{a, c, s, t\}, K, \{r_0, r_1, r_2, r_3\})$ with $\omega_0(c_0) = \{(t,a)\}$, $\omega_2(a_2) = \{(s,c)\}$, $\omega_2(c_2) = \{(s,a),(t,a)\}$, $\omega_1 = \omega_3 = \emptyset$ being the complete characterization of the embedding functions of the respective rules, and the the rules being denoted as below. We advise that PAC vertices and their adjacent edges are depicted with dotted lines.

\input{examples/classdiagram-pacgg}

Below, we demonstrate that the graph from Figure \ref{fig:classdiagram-g} is in $L(GG)$, by means of a production in $GG$.
\input{examples/classdiagram-pacder}

\begin{remark}
	If, for all rules $(A \pro R,\omega,U)$ in a grammar $GG$ have $U = \emptyset$, then the $GG$ degrades to a normal NCE grammar without PAC and the resolution steps have no effect in $L(GG)$.
\end{remark}

\begin{remark}
	Given a graph grammar $GG$ with PAC, if the graph $g$ is in $L(GG)$, then $g$ has no PAC vertices. That is, the resolution steps remove all PAC vertices, because every resolution function $\rho_i$ is required to map to vertices that are not in its domain. This guarantees that the number of PAC vertices reduces at each resolution step with $\rho_i \neq \emptyset$.
\end{remark}

Regarding the parsing procedure, the Algorithm \ref{alg:parse} can be slightly modified to support PAC, by augmenting the zone vertices with PAC vertices, changing the way how zone graphs are constructed and how zone vertices are added to $bup$ and to the parsing forest. The details of these changes are described in the sequel.

\begin{definition}
	A zone vertex with PAC of a graph $G$ is a triple $(\sigma, U, W)$, with $\sigma$ and $U$ being as explained in Definition \ref{def:zv} and $W \in V_G$ being the set of PAC vertices disjunct from $U$.
\end{definition}

\begin{definition}
	Let $H = \{(\sigma_o,U_0,W_0), \dots, (\sigma_m, U_m, W_m)\})$ be a set of zone vertices with PAC of a graph $G$, as given in Definition \ref{def:z}, and $W(H) = \bigcup_{0 \le i \le m}{W_i}$. A zone graph with PAC $Z(H)$ for $H$ is $(V,E,\psi)$, with
	\begin{align*}
		V & = H \cup \{(\psi_G(x),\{x\}, \emptyset) \st x \in \neigh{G}(V(H)) \setminus W(H) \} \\
		E & = \{((\sigma,U,W),l,(\eta,T,X)) \st (\sigma,U,W),(\eta,T,X) \in V \text{ and } U \neq T \text{ and } \\
		& (u,l,t) \in E_G \text{ and } u \in U \setminus X \text{ and } t \in T \setminus W \} \\
		\phi & = \{(\sigma,U,W) \mapsto \sigma \st (\sigma,U,W) \in V\}
	\end{align*}
\end{definition}

%TODO: Probably need to explain better Q, based on the explanation about D
The Algorithm \ref{alg:parsepac} is a parsing method that returns a valid derivation if, and only if, the input graph $G$ is in the language of the graph grammar $GG$ with PAC. Notice that, this procedure does not return a derivation, but a production, that is built by the function $Q$ that performs, analogously to $D$ in Algorithm \ref{alg:parse}, a depth-first walk in the parsing tree.

\begin{algorithm}[!h]
	\caption{Parsing Algorithm for NP BNCE Graph Grammars with PAC}
	\begin{algorithmic}[1]
		\Require $GG \text{ is a valid NP BNCE graph grammar with PAC}$
		\Require $G \text{ is a valid graph over } \Delta$
		\Function{$parse$}{$GG=(\Sigma, \Delta, S, P), G=(V_G,E_G,\phi_G)$}{$:Derivation$}
		\State $bup \gets \{(\phi_G(x),\{x\},\emptyset) \st x \in V_G\}$
		\State $pf \gets \{ \ptree{b}{}{\emptyset} \st b \in bup \}$
		\Repeat
		\State $h \gets \text{\Select } \{X \subseteq bup \st\text{for all } U_i, U_j \in X \text{ with } i \neq j \. U_i \cap U_j = \emptyset \}$
		\ForAll{$d \in \Gamma$}
		\State $r \gets \text{any } \{(d \pro R,\omega,U) \in P \st R \isomorph Y(h) \}$
		\State $l \gets (d,V(h)\setminus W(h), W(h))$ \Comment{$l$ is augmented with PAC $W(h)$}
		\If{$Z(\{l\}) \derivpac{r}{l}{W}{} Z(h)$} \Comment{derivation with PAC is possible}
		\State $bup \gets bup \cup \{l\}$
		\State $pf \gets pf \cup \{ \ptree{l}{r}{\{\ptree{z}{y}{X} \st \ptree{z}{y}{X} \in pf, z \in h \}} \}$
		\EndIf
		\EndFor
		\Until{$(S, V_G, \_) \in bup$} \Comment{if found the root, no matter which PAC}
		\State \Return $(S, V_G, \_) \in bup \? \Just Q(\ptree{(S,V_G, \_)}{y}{X} \in pf) \: \Nothing $
		\EndFunction
		\Ensure $return \text{ is either } \Nothing \text{ or of the form } \Just \startG{GG} \derivpactr{} G \resolvtr{}$
	\end{algorithmic}
	\label{alg:parsepac}
\end{algorithm}

The most important difference between Algorithm \ref{alg:parse} and \ref{alg:parsepac} are, first, in the use of a derivation with PAC $Z(\{l\}) \derivpac{r}{l}{W}{} Z(h)$ in line 9, where $W$ is the set of PAC vertices $U$ from the rule $r$ mapped to the zone graph $Z(h)$, and, second, in the construction of the zone vertex $l$, that is augmented with the PAC vertices $W(h)$ which are, in turn, removed from the normal vertices of $l$, in line 8. In practice, this allows, on the one hand, that PAC vertices participate in the search for rules that produce the desired zone graphs, and, on the other hand, that they be not included in the set of normal vertices of zone vertices so they can be effectively added to the zone vertices that effectively produce them.

The extension of NCE TGG to support PAC is straightforward. 

\begin{definition}
	A triple rule with PAC is of the form $(A \pro (R_s \ms{} R_c \mt{} R_t), \omega_s, \omega_t, U_s, U_t)$ with $A \pro (R_s \ms{} R_c \mt{} R_t)$, $\omega_s$, and $\omega_t$ as defined in Definition \ref{def:tgg} and $U_s \subseteq \{v \in V_{R_s} \st \phi_{R_s}(v) \in \Delta\}$ the set of PAC vertices of $R_s$ and $U_t \subseteq \{v \in V_{R_t} \st \phi_{R_t}(v) \in \Delta\}$ the set of PAC vertices of $R_t$.
\end{definition}

Analogously, the concepts of \textit{concrete derivation step} and \textit{derivation step} for TGG are extended to be as follows.

\begin{definition}
 A \textit{concrete derivation step} with PAC in the triple graph grammar $TGG$ is of the form $G \tcderivpac{r}{v_s,v_c,v_t}{U_s,U_t}{TGG} H$, where $G$, $H$, $v_s$, $v_c$, $v_t$ being as described in Definition \ref{def:tgg_dstep}, $r = (A \pro (R_s \ms{} R_c \mt{} R_t), \omega_s, \omega_t, U_s, U_t)$ being a triple rule with PAC. Given that, a \textit{derivation step} with PAC is, analogously, of the form $G \tderivpac{r}{v_s,v_c,v_t}{W_s,W_t}{TGG} H'$ with $W_s = m(U_s)$ and $W_t = m(U_t)$ where $m$ is the triple isomorphism from $H$ to $H'$.
\end{definition}

Moreover, the \textit{resolution step} for TGG is as follows.

\begin{definition}
	Let $TGG = (\Sigma, \Delta, S, P)$ be a triple graph grammar and $G = (G_s \ms{g_s} G_c \mt{g_t} G_t)$ a triple graph over $\Delta$, $G$ resolves into $H = (H_s \ms{h_s} H_c \mt{h_t} H_t)$ with the resolution partial functions $\rho_s: V_{G_s} \pto V_{G_s}$ and $\rho_t: V_{G_t} \pto V_{G_t}$, we write $G \tresolv{\rho_s, \rho_t} H$ and call it a resolution step, if, and only if, the following holds:
	\begin{align*}
	& \forall v \in \dom \rho_s \. \rho_s(v) \notin \dom \rho_s \text{ and } \phi_{G_s}(\rho_s(v)) = \phi_{G_s}(v) \text{ and}\\
	& \forall v \in \dom \rho_t \. \rho_t(v) \notin \dom \rho_t \text{ and } \phi_{G_t}(\rho_t(v)) = \phi_{G_t}(v) \text{ and}\\
	V_{H_s} & = V_{G_s} \setminus \dom  \rho_s\text{ and}\\
	V_{H_c} & = V_{G_c} \setminus g_s^{-1}(\dom  \rho_s) \text{ and}\\
	V_{H_t} & = V_{G_t} \setminus \dom  \rho_t\text{ and}\\
	E_{H_s} & = (E_{G_s} \setminus (\{(u,l,t) \st u \in \dom \rho_s, (u,l,t) \in E_{G_s}\} \\
			&\hspace{3.5em} \cup \{(t,l,u) \st u \in \dom \rho_s, (t,l,u) \in E_{G_s}\}))\\
	& \cup \{(\rho_s(u),l,t) \st u \in \dom \rho_s, (u,l,t) \in E_{G_s}\} \\
	& \cup \{(t,l,\rho_s(u)) \st u \in \dom \rho_s, (t,l,u) \in E_{G_s}\} \\
	E_{H_c} & = E_{G_c} \setminus (\{(u,l,t) \st u \in g_s^{-1}(\dom \rho_s), (u,l,t) \in E_{G_c}\} \\
			&\hspace{3.5em} \cup \{(t,l,u) \st u \in g_s^{-1}(\dom \rho_s), (t,l,u) \in E_{G_c}\})\\
	E_{H_t} & = (E_{G_t} \setminus (\{(u,l,t) \st u \in \dom \rho_t, (u,l,t) \in E_{G_t}\} \\
	&\hspace{3.5em} \cup \{(t,l,u) \st u \in \dom \rho_t, (t,l,u) \in E_{G_t}\}))\\
	& \cup \{(\rho_t(u),l,t) \st u \in \dom \rho_t, (u,l,t) \in E_{G_t}\} \\
	& \cup \{(t,l,\rho_t(u)) \st u \in \dom \rho_t, (t,l,u) \in E_{G_t}\}
	\end{align*}
\end{definition}


In regard to the application of NCE graph grammars with PAC to the problem of model transformation, the extension is also possible, as shown in the next argumentation. First, consider the redefinition of the $\source$ function.

\begin{definition}
	\label{def:sourcepac}
	Let $r = (A \pro (G_s \ms{} G_c \mt{} G_t), \omega_s, \omega_t, U_s, U_t)$ be a production rule of a triple graph grammar, redefine $\source(r)$ as $\source(r) = (A \pro G_s,\omega_s,U_s)$ and $\source^{-1}((A \pro G_s,\omega_s,U_s)) = r$.
\end{definition}

Furthermore, consider the definition of the PAC consistent (PC) property of TGG, which assures that a PAC vertex of the source graph is connected with a PAC vertex in the correspondence and in the target graphs.

\begin{definition}
	A triple graph grammar $TGG = (\Sigma, \Delta, S, P)$ is PAC consistent (PC) if and only if, for all rules $(A \pro (G_s \ms{m_s} G_c \mt{m_t} G_t), \omega_s, \omega_t, U_s, U_t) \in P$, $\forall v \in U_s \. m_t(m_s^{-1}(v)) \in U_t$ and $\forall v \in U_t \. m_s(m_t^{-1}(v)) \in U_s$.
\end{definition}

Finally, the following Theorem \ref{thm:one_d_enough_pac} is an extended equivalent to the Theorem \ref{thm:one_d_enough}, which allows us to construct a production in $TGG$ out of a production in $S(TGG)$, for a triple graph grammar $TGG$.

\begin{theorem}
	\label{thm:one_d_enough_pac}
	Let $TGG = (\Sigma, \Delta, S, P)$ be a NTC PC TGG and $k \ge 1$, \\
	$Q = \startTG{TGG} \tderivpac{r_0}{s_0,c_0,t_0}{W_0,Y_0}{} G^1 \tderivpac{r_1}{s_1,c_1,t_1}{W_1,Y_1}{} \dots \tderivpac{r_{k-1}}{s_{k-1},c_{k-1},t_{k-1}}{W_{k-1},Y_{k-1}}{} G^k$\\
	$ \tresolv{\rho_0,\tau_0} H^1 \tresolv{\rho_1,\tau_1} \dots \tresolv{\rho_{k-1},\tau_{k-1}} H^k$ is a production in $TGG$ if, and only if, $\overline{Q} = \startG{S(TGG)} \derivpac{s(r_0)}{s_0}{W_0}{} G^1_s \derivpac{s(r_1)}{s_1}{W_1}{} \dots \derivpac{s(r_{k-1})}{s_{k-1}}{W_{k-1}}{} G^k_s \tresolv{\rho_0} H_s^1 \tresolv{\rho_1} \dots \tresolv{\rho_{k-1}} H_s^k$ is a production in $S(TGG)$.
\end{theorem}
\begin{proof}
	...
	%TODO
\end{proof}

The effective transformation procedure for TGG with PAC is essentially the same as the one in Algorithm \ref{alg:transform}, with the additional requirement of TGG being PC and the use of Theorem \ref{thm:one_d_enough_pac} to derive and resolve PAC vertices for the produced triple graph.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%% IMPLEMENTATION %%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Implementation}
Concrete implementation. Critical view.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%% EVALUATION %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Evaluation}
In order to evaluate the proposed BNCE TGG formalism, we compare the amount of rules and elements (vertices, edges and mappings) we needed to describe some typical model transformations in BNCE TGG and in standard TGG without application conditions. Table \ref{tab:formalism-eval} presents these results.
\begin{table}[h]
	\centering
	\begin{tabular}{l r r r r }
						& \multicolumn{2}{c}{Standard TGG} & \multicolumn{2}{c}{BNCE TGG}\\
		Transformation 			& Rules & Elements 	& Rules & Elements\\
		\hline
		Pseudocode2Controlflow	& 45			& 1061	& \textbf{7}	& \textbf{185} \\
		BTree2XBTree			& \textbf{4}	& \textbf{50}	& 5		& 80 \\
		Star2Wheel				& -				& -		& \textbf{6} 	& \textbf{89} \\
		%Activity2ControlFlow	& 	&	&	&	\\
		%StateMachine2PetriNets	& 	&	&	&	\\
		%UMLClass2SDLBlock		& 	&	&	&	\\
		%Code2ControlFlow 		& 	&	&	&	\\
		%Activity2CSP \\
		%\citep{Bisztray2009}			& 	&	&	&	\\
		%StateMachine2Java \\
		%\citep{Striewe2008}		& 	&	&	&	\\
		\hline
		Total					&  & 		&	& \\
		Average					&  & 		&	& \\
	\end{tabular}
	\caption{Results of the usability evaluation of the BNCE TGG formalism in comparison with the standard TGG for the model transformation problem}
	\label{tab:formalism-eval}
\end{table}

In the case of $Pseudocode2Controlflow$, our proposed approach shows a clear advantage against the standard TGG formalism. We judge that, similarly to what happens to programming languages, this advantage stems from the very nested structure of $Pseudocode$ and $Controlflow$ graphs. That is, for instance, in rule the $r_2$ of this TGG (see Example \ref{ex:pseudocode2controlflow}), a node in a positive branch of an $if$-labeled vertex is never connected with a node in the negative branch. This disjunctive aspect allows every branch to be defined in the rule (as well as effectively parsed) independently of the other branch. This characteristic makes it possible for BNCE TGG rules to be defined in a very straightforward manner and reduces the total amount of elements necessary.

In addition to that, the use of non-terminal symbols gives BNCE TGG the power to represent abstract concepts very easily. For example, whereas the rule $r_1$ encodes, using only few elements, that after each $action$ comes any statement $A$, which can be another $action$, an $if$, a $while$ or nothing (an empty graph), in the standard TGG without application condition or any special inheritance treatment, we need to write a different rule for each of these cases. For the whole grammar, we need to consider all combinations of $actions$, $ifs$ and $whiles$ in all rules, what causes the great amount of rules and elements.

The $Star2Wheel$ transformation consists of transforming star graphs, which are complete bipartite graphs $K_{1,k}$, with the partitions named center and border, to wheel graphs, that can be constructed from star graphs by adding edges between border vertices to form a minimal cycle. We could not write this transformation in standard TGG, specially because of the rules' monotonicity (see Definition \ref{def:stgg}). That is, we missed the possibility to erase edges in a rule, feature that we do have in the semantics of BNCE TGG through the embedding mechanism.

%TODO: Positive and negative aspects of the proposed approach. Cases where it specially works good and bad. 
%TODO: Overview: total and average results

%TODO: Not enough experimentation to say one is expressive than the other. This would require extensive theoretical analysis. But BNCE seems to present better usability in many cases

%TODO: Cite s_78 for evaluation of HRGs

%TODO: Expressiviness. Run away from nacs and tacs. with NCE

%Furthermore, we also report on the runtime for forward and backward batch transformations in a Intel Core i3 2.3GHz 4x 64bit with 4GB RAM. The standard TGG version of the transformations were executed using the eMoflon Tool \cite{leblebici2014developing}.
\begin{table}[h]
	\centering
	\begin{tabular}{l r r r r }
			& \multicolumn{2}{c}{Standard TGG} & \multicolumn{2}{c}{BNCE TGG}\\
		Transformation 	& Forward & Backward & Forward & Backward \\
		\hline
		Pseudocode2Controlflow	& 		& 		& 	 	&  \\
		BTree2XBTree			&  		& 		& 		&  \\
		Star2Wheel				& -		& -		& 	 	&  \\
		\hline
		Total					&  & 		&	& \\
		Average					&  & 		&	& \\
	\end{tabular}
	\caption{Results of the empirical evaluation of the B-NLC TGG in comparison with standard TGG}
	\label{tab:evaluation}
\end{table}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% CONCLUSION %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Conclusion}
Summary and closing words. Future work (e.g. lexicalization for model synchronization).

%TODO cite: s_52,s_93

\bibliographystyle{plain}
\bibliography{bibliography}
\end{document}          
